{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Vampire-Chan/SDUI/blob/main/ComfyUI.ipynb)\n"
      ],
      "metadata": {
        "id": "E8Oq-2xfaZSB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **ComfyUI Environment Auto-Setup with Update Support**\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# ✅ User-configurable options\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "\n",
        "# ✅ Define workspace path\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    print(\"🔗 Mounting Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "else:\n",
        "    WORKSPACE = \"./ComfyUI\"\n",
        "\n",
        "COMFY_REPO = \"https://github.com/comfyanonymous/ComfyUI\"\n",
        "MANAGER_REPO = \"https://github.com/ltdrdata/ComfyUI-Manager.git\"\n",
        "CUSTOM_NODES_DIR = os.path.join(WORKSPACE, \"custom_nodes\", \"ComfyUI-Manager\")\n",
        "\n",
        "# ✅ Clone or update ComfyUI\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    print(\"📂 Cloning ComfyUI for the first time...\")\n",
        "    os.system(f\"git clone {COMFY_REPO} {WORKSPACE}\")\n",
        "else:\n",
        "    if UPDATE_COMFY_UI:\n",
        "        print(\"🔄 Updating ComfyUI...\")\n",
        "        os.chdir(WORKSPACE)\n",
        "        os.system(\"git reset --hard\")\n",
        "        os.system(\"git pull origin master\")\n",
        "    else:\n",
        "        print(\"⏭️ Skipping ComfyUI update.\")\n",
        "\n",
        "# ✅ Clone or update ComfyUI-Manager\n",
        "if not os.path.exists(CUSTOM_NODES_DIR):\n",
        "    print(\"📂 Cloning ComfyUI-Manager for the first time...\")\n",
        "    os.system(f\"git clone {MANAGER_REPO} {CUSTOM_NODES_DIR}\")\n",
        "else:\n",
        "    if UPDATE_COMFY_UI:\n",
        "        print(\"🔄 Updating ComfyUI-Manager...\")\n",
        "        os.chdir(CUSTOM_NODES_DIR)\n",
        "        os.system(\"git reset --hard\")\n",
        "        os.system(\"git pull origin main\")\n",
        "    else:\n",
        "        print(\"⏭️ Skipping ComfyUI-Manager update.\")\n",
        "\n",
        "# ✅ Install dependencies\n",
        "os.chdir(WORKSPACE)\n",
        "print(\"📦 Installing dependencies...\")\n",
        "os.system(\n",
        "    \"pip install xformers!=0.0.18 -r requirements.txt \"\n",
        "    \"--extra-index-url https://download.pytorch.org/whl/cu121 \"\n",
        "    \"--extra-index-url https://download.pytorch.org/whl/cu118 \"\n",
        "    \"--extra-index-url https://download.pytorch.org/whl/cu117\"\n",
        ")\n",
        "\n",
        "print(\"✅ Environment setup and update complete.\")\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dddddddddd",
        "cellView": "form",
        "outputId": "06c2c604-9229-4e88-cd0f-eb111e85d82e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "⏳ Starting download for https://civitai.com/api/download/models/1671255?type=Model&format=SafeTensor to the 'loras' directory...\n",
            "❌ Error downloading https://civitai.com/api/download/models/1671255?type=Model&format=SafeTensor: 401 Client Error: Unauthorized for url: https://civitai.com/api/download/models/1671255?type=Model&format=SafeTensor\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "import urllib.parse\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# 🔥 Custom Colab Form Inputs\n",
        "MODEL_URL = \"https://civitai.com/api/download/models/1671255?type=Model&format=SafeTensor\"  #@param {type:\"string\"}\n",
        "API_KEY = \"\"  #@param {type:\"string\"}\n",
        "MODEL_TYPE = \"loras\"  #@param [\"checkpoints\", \"clip_vision\", \"vae\", \"loras\", \"controlnet\", \"style_models\", \"upscale_models\", \"diffusion_models\", \"hypernetworks\", \"gligen\", \"custom_nodes\"]\n",
        "SAVE_TO_DRIVE = True  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_FOLDER = False  #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup the base directory dynamically based on user options.\"\"\"\n",
        "    if SAVE_TO_DRIVE:\n",
        "        print(\"🔗 Mounting Google Drive...\")\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        base_dir = '/content/drive/MyDrive/ComfyUI'\n",
        "    else:\n",
        "        base_dir = './ComfyUI' if USE_COMFYUI_FOLDER else './content/sdui'\n",
        "    return base_dir\n",
        "\n",
        "\n",
        "# Human-readable time formatter for ETA\n",
        "def human_readable_time(seconds):\n",
        "    if seconds >= 3600:\n",
        "        return f\"{int(seconds // 3600)}h {int((seconds % 3600) // 60)}m {int(seconds % 60)}s\"\n",
        "    elif seconds >= 60:\n",
        "        return f\"{int(seconds // 60)}m {int(seconds % 60)}s\"\n",
        "    else:\n",
        "        return f\"{int(seconds)}s\"\n",
        "\n",
        "\n",
        "# Human-readable size formatter for bytes to KB, MB, GB\n",
        "def human_readable_size(byte_count):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(byte_count) < 1024.0:\n",
        "            return f\"{byte_count:3.1f}{unit}B\"\n",
        "        byte_count /= 1024.0\n",
        "    return f\"{byte_count:.1f}PB\"\n",
        "\n",
        "\n",
        "def format_progress_bar(percent, bar_length=30):\n",
        "    \"\"\"Create a text-based progress bar similar to pip.\"\"\"\n",
        "    filled_length = int(bar_length * percent // 100)\n",
        "    bar = '█' * filled_length + '-' * (bar_length - filled_length)\n",
        "    return f\"[{bar}]\"\n",
        "\n",
        "\n",
        "def download_file(url, save_path, api_key=None):\n",
        "    \"\"\"Download a file from a given URL and save it to the specified path with a progress bar, percentage, time left, and download speed.\"\"\"\n",
        "    try:\n",
        "        headers = {}\n",
        "        if api_key:\n",
        "            headers['Authorization'] = f'Bearer {api_key}'\n",
        "\n",
        "        response = requests.get(url, stream=True, allow_redirects=True, headers=headers)\n",
        "\n",
        "        # Retry with API key if access denied and no API key used yet\n",
        "        if response.status_code == 403 and not api_key:\n",
        "            print(\"⚠️ Access denied. Retrying with API key...\")\n",
        "            return download_file(url, save_path, api_key=API_KEY)\n",
        "\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Determine filename\n",
        "        filename = os.path.basename(urllib.parse.urlparse(url).path)\n",
        "        if 'content-disposition' in response.headers:\n",
        "            import cgi\n",
        "            _, params = cgi.parse_header(response.headers['content-disposition'])\n",
        "            filename = params.get('filename', filename)\n",
        "\n",
        "        save_path = os.path.join(save_path, filename)\n",
        "\n",
        "        total_size = int(response.headers.get('Content-Length', 0))\n",
        "        downloaded = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        with open(save_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "                    downloaded += len(chunk)\n",
        "\n",
        "                    percent = (downloaded / total_size) * 100 if total_size else 0\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    speed = (downloaded / (1024 * 1024)) / elapsed_time if elapsed_time > 0 else 0  # MB/s\n",
        "                    remaining = total_size - downloaded\n",
        "                    time_left = (remaining / (speed * 1024 * 1024)) if speed > 0 else 0\n",
        "\n",
        "                    progress_bar = format_progress_bar(percent)\n",
        "                    speedstr = f\"{speed:.2f} MB/s\"\n",
        "                    timestr = human_readable_time(time_left)\n",
        "\n",
        "                    sys.stdout.write(\n",
        "                        f\"\\rDownloading {filename} {progress_bar} {percent:6.2f}% | \"\n",
        "                        f\"{human_readable_size(downloaded)} / {human_readable_size(total_size)} | \"\n",
        "                        f\"{speedstr} | ETA: {timestr}  \"\n",
        "                    )\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "        print(f\"\\n✅ Downloaded: {filename} to {save_path} - Total Size: {human_readable_size(total_size)}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"❌ Error downloading {url}: {e}\")\n",
        "\n",
        "\n",
        "# 🌍 Start setup environment\n",
        "BASE_DIR = setup_environment()\n",
        "\n",
        "# Define all possible model directories from extra_model_paths.yaml\n",
        "MODEL_DIRS = {\n",
        "    'checkpoints': 'models/checkpoints',\n",
        "    'clip_vision': 'models/clip_vision',\n",
        "    'vae': 'models/vae',\n",
        "    'loras': 'models/loras',\n",
        "    'controlnet': 'models/controlnet',\n",
        "    'style_models': 'models/style_models',\n",
        "    'upscale_models': 'models/upscale_models',\n",
        "    'diffusion_models': 'models/diffusion_models',\n",
        "    'hypernetworks': 'models/hypernetworks',\n",
        "    'gligen': 'models/gligen',\n",
        "    'custom_nodes': 'path/custom_nodes',\n",
        "    'clip': 'models/clip',\n",
        "    'configs': 'models/configs',\n",
        "}\n",
        "\n",
        "# Update model paths to use Google Drive, ComfyUI, or content/sdui\n",
        "MODEL_DIRS = {key: os.path.join(BASE_DIR, path) for key, path in MODEL_DIRS.items()}\n",
        "\n",
        "# Create directories if they do not exist\n",
        "for path in MODEL_DIRS.values():\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "# 🌍 Start model download\n",
        "if MODEL_URL:\n",
        "    print(f\"⏳ Starting download for {MODEL_URL} to the '{MODEL_TYPE}' directory...\")\n",
        "    save_path = MODEL_DIRS.get(MODEL_TYPE, os.path.join(BASE_DIR, 'models'))\n",
        "    download_file(MODEL_URL, save_path, api_key=API_KEY)\n",
        "else:\n",
        "    print(\"❌ No URL provided for download.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "cellView": "form",
        "outputId": "ddfda261-dfe3-48ae-b7c4-673e620584f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "📁 Using storage at: /content/drive/MyDrive/ComfyUI\n",
            "🚀 CUDA Available!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ba8568a5b26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0minstall_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# ✅ Download and install Cloudflared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2ba8568a5b26>\u001b[0m in \u001b[0;36minstall_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"📦 Installing missing module: {module}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanonicalize_state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_registry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAIN_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from .__helpers.model_descriptor import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/__helpers/loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcanonicalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanonicalize_state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmain_registry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAIN_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_descriptor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelDescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStateDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArchRegistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/__helpers/main_registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from ..architectures import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mATD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mCRAFT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/architectures/DAT/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mStateDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__arch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDAT\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/architectures/DAT/__arch/DAT.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meinops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRearrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/layers/torch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRearrangeMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReduceMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_einmix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_EinmixMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_specific\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_for_scriptable_torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0m__author__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Alex Rogozhnikov\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/_torch_specific.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# module import automatically registers ops in torchdynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mallow_ops_in_compiled_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/_torch_specific.py\u001b[0m in \u001b[0;36mallow_ops_in_compiled_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallow_in_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_ops_in_compiled_graph failed to import torch: ensure pytorch >=2.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "#@title **ComfyUI Launcher**\n",
        "#@markdown Launch ComfyUI for Stable Diffusion on Colab.\n",
        "#@markdown Uncheck **Google Drive** if running locally.\n",
        "#@markdown If ComfyUI fails with \"module not found,\" add the missing module to **required_modules**.\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "from google.colab import drive\n",
        "\n",
        "# ✅ User options\n",
        "mount_gdrive = True  #@param {type:\"boolean\"}\n",
        "required_modules = ['torch', 'flask', 'flask_cors', 'requests', 'torchsde', 'spandrel', 'kornia', 'piexif', 'segment_anything']  #@param\n",
        "\n",
        "# ✅ Step 1: Mount Google Drive if selected\n",
        "folder_path = \"/content/ComfyUI\"\n",
        "if mount_gdrive:\n",
        "    print(\"🔗 Mounting Google Drive...\")\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        folder_path = \"/content/drive/MyDrive/ComfyUI\"\n",
        "        print(\"✅ Google Drive mounted successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error mounting Google Drive: {e}\")\n",
        "        exit(1)\n",
        "else:\n",
        "    print(\"🖥️ Running without Google Drive.\")\n",
        "\n",
        "# ✅ Step 2: Check CUDA availability\n",
        "def check_cuda():\n",
        "    import torch\n",
        "    print(\"🚀 CUDA Available!\" if torch.cuda.is_available() else \"⚠️ No GPU found, running on CPU.\")\n",
        "check_cuda()\n",
        "\n",
        "# ✅ Step 3: Install missing modules\n",
        "def install_module(module):\n",
        "    try:\n",
        "        __import__(module)\n",
        "    except ModuleNotFoundError:\n",
        "        print(f\"❌ Module '{module}' not found, installing...\")\n",
        "        os.system(f\"pip install {module}\")\n",
        "        print(f\"✅ Module '{module}' installed!\")\n",
        "\n",
        "for mod in required_modules:\n",
        "    install_module(mod)\n",
        "\n",
        "# ✅ Step 4: Download & Install Cloudflared\n",
        "def download_and_install_cloudflared():\n",
        "    url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\"\n",
        "    deb_path = os.path.join(folder_path, \"cloudflared.deb\")\n",
        "\n",
        "    print(\"📥 Downloading Cloudflared...\")\n",
        "    if os.system(f\"wget --progress=bar:force {url} -O {deb_path}\") != 0:\n",
        "        print(\"❌ Failed to download Cloudflared.\")\n",
        "        exit(1)\n",
        "\n",
        "    print(\"🛠️ Installing Cloudflared...\")\n",
        "    if os.system(f\"dpkg -i {deb_path}\") != 0:\n",
        "        print(\"❌ Cloudflared installation failed.\")\n",
        "        exit(1)\n",
        "\n",
        "    print(\"✅ Cloudflared is installed!\")\n",
        "download_and_install_cloudflared()\n",
        "\n",
        "# ✅ Step 5: Launch ComfyUI & Monitor Cloudflared\n",
        "def launch_cloudflared(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
        "            if sock.connect_ex(('127.0.0.1', port)) == 0:\n",
        "                break\n",
        "\n",
        "    print(\"\\n🎉 ComfyUI is ready, launching Cloudflared...\\n\")\n",
        "    process = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    for line in process.stderr:\n",
        "        l = line.decode()\n",
        "        if \"trycloudflare.com\" in l:\n",
        "            print(\"🔗 Access ComfyUI at:\", l[l.find(\"http\"):], end='')\n",
        "\n",
        "threading.Thread(target=launch_cloudflared, daemon=True, args=(8188,)).start()\n",
        "\n",
        "# ✅ Step 6: Start ComfyUI\n",
        "print(\"🚀 Starting ComfyUI...\")\n",
        "os.system(f\"python {os.path.join(folder_path, 'main.py')} --dont-print-server\")"
      ]
    },
    {
      "source": [
        "#@title **📦 Compress & Clean Output Folder**\n",
        "#@markdown Use this tool to compress your output folder and clean it after.\n",
        "#@markdown Choose file format, compression level, and destination.\n",
        "!pip install py7zr\n",
        "!pip install rarfile\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import sys\n",
        "import subprocess\n",
        "import py7zr\n",
        "import rarfile\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# ✅ **Mount Google Drive**\n",
        "mount_gdrive = True  #@param {type:\"boolean\"}\n",
        "if mount_gdrive:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# ✅ **User Options**\n",
        "output_folder = \"/content/drive/MyDrive/ComfyUI/output\"  #@param {type: \"string\"}\n",
        "archive_name = \"output\"  #@param {type: \"string\"}\n",
        "archive_destination = \"/content/drive/MyDrive/\"  #@param {type: \"string\"}\n",
        "\n",
        "file_type = \"zip\"  #@param [\"zip\", \"7z\", \"rar\"]\n",
        "compression_level = \"normal\"  #@param [\"store\", \"fast\", \"normal\", \"high\", \"maximum\"]\n",
        "\n",
        "# 🔥 **Compression Level Mapping**\n",
        "compression_map = {\n",
        "    'store': 0, 'fast': 1, 'normal': 5, 'high': 7, 'maximum': 9\n",
        "}\n",
        "\n",
        "def compress_and_clean_output(output_folder, archive_name, archive_destination, file_type, compression_level):\n",
        "    \"\"\"Compresses and cleans the output folder.\"\"\"\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        print(f\"❌ Error: The folder '{output_folder}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(archive_destination):\n",
        "        print(f\"❌ Error: The destination folder '{archive_destination}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    total_original_size = sum(\n",
        "        os.path.getsize(os.path.join(root, file))\n",
        "        for root, _, files in os.walk(output_folder)\n",
        "        for file in files\n",
        "    )\n",
        "\n",
        "    extension = {'zip': '.zip', '7z': '.7z', 'rar': '.rar'}[file_type]\n",
        "    archive_path = os.path.join(archive_destination, f\"{archive_name}{extension}\")\n",
        "    compression_value = compression_map[compression_level]\n",
        "\n",
        "    # ✅ **ZIP Compression**\n",
        "    if file_type == 'zip':\n",
        "        compression = zipfile.ZIP_STORED if compression_level == 'store' else zipfile.ZIP_DEFLATED\n",
        "        with zipfile.ZipFile(archive_path, 'w', compression) as zipf:\n",
        "            for root, _, files in os.walk(output_folder):\n",
        "                for file in tqdm(files, desc=\"📦 Compressing as .zip\", unit=\"file\"):\n",
        "                    zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), output_folder))\n",
        "\n",
        "    # ✅ **7Z Compression**\n",
        "    elif file_type == '7z':\n",
        "        with py7zr.SevenZipFile(archive_path, 'w', filters=[{'id': py7zr.FILTER_LZMA2, 'preset': compression_value}]) as archive:\n",
        "            for root, _, files in os.walk(output_folder):\n",
        "                for file in tqdm(files, desc=\"📦 Compressing as .7z\", unit=\"file\"):\n",
        "                    archive.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), output_folder))\n",
        "\n",
        "    # ✅ **RAR Compression**\n",
        "    elif file_type == 'rar':\n",
        "        try:\n",
        "            print(\"📦 Compressing as .rar (This may take some time, progress bar not supported)\")\n",
        "            subprocess.run(['rar', 'a', '-m' + str(compression_value), archive_path, output_folder], check=True)\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(\"❌ Failed to create .rar archive. Install 'rar' using 'apt-get install rar'.\")\n",
        "\n",
        "    total_compressed_size = os.path.getsize(archive_path)\n",
        "    compression_percentage = (1 - (total_compressed_size / total_original_size)) * 100 if total_original_size > 0 else 0\n",
        "\n",
        "    print(f\"📦 Original size: {total_original_size / 1024**2:.2f} MB\")\n",
        "    print(f\"📦 Compressed size: {total_compressed_size / 1024**2:.2f} MB\")\n",
        "    print(f\"📦 Compression percentage: {compression_percentage:.2f}%\")\n",
        "\n",
        "    # ✅ **Delete original files**\n",
        "    for filename in os.listdir(output_folder):\n",
        "        file_path = os.path.join(output_folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'❌ Failed to delete {file_path}. Reason: {e}')\n",
        "\n",
        "    print(f\"✅ Successfully compressed and cleaned {output_folder}\")\n",
        "\n",
        "# 🔥 **Run the function**\n",
        "compress_and_clean_output(output_folder, archive_name, archive_destination, file_type, compression_level)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "devAdoTZi_Qa",
        "outputId": "2507d99d-d23a-4a03-cc94-f2a185d50d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (3.22.0)\n",
            "Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.11/dist-packages (from py7zr) (0.16.2)\n",
            "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.1.1)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.0.3)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.0.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr) (5.9.5)\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📦 Compressing as .zip: 100%|██████████| 70/70 [00:18<00:00,  3.85file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Original size: 336.22 MB\n",
            "📦 Compressed size: 335.62 MB\n",
            "📦 Compression percentage: 0.18%\n",
            "✅ Successfully compressed and cleaned /content/drive/MyDrive/ComfyUI/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZ1B9CWu-CJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}