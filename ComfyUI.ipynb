{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Vampire-Chan/SDUI/blob/main/ComfyUI.ipynb)\n"
      ],
      "metadata": {
        "id": "E8Oq-2xfaZSB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **ComfyUI Environment Auto-Setup with Update Support**\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# ‚úÖ User-configurable options\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "\n",
        "# ‚úÖ Define workspace path\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "else:\n",
        "    WORKSPACE = \"./ComfyUI\"\n",
        "\n",
        "COMFY_REPO = \"https://github.com/comfyanonymous/ComfyUI\"\n",
        "MANAGER_REPO = \"https://github.com/ltdrdata/ComfyUI-Manager.git\"\n",
        "CUSTOM_NODES_DIR = os.path.join(WORKSPACE, \"custom_nodes\", \"ComfyUI-Manager\")\n",
        "\n",
        "# ‚úÖ Clone or update ComfyUI\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    print(\"üìÇ Cloning ComfyUI for the first time...\")\n",
        "    os.system(f\"git clone {COMFY_REPO} {WORKSPACE}\")\n",
        "else:\n",
        "    if UPDATE_COMFY_UI:\n",
        "        print(\"üîÑ Updating ComfyUI...\")\n",
        "        os.chdir(WORKSPACE)\n",
        "        os.system(\"git reset --hard\")\n",
        "        os.system(\"git pull origin master\")\n",
        "    else:\n",
        "        print(\"‚è≠Ô∏è Skipping ComfyUI update.\")\n",
        "\n",
        "# ‚úÖ Clone or update ComfyUI-Manager\n",
        "if not os.path.exists(CUSTOM_NODES_DIR):\n",
        "    print(\"üìÇ Cloning ComfyUI-Manager for the first time...\")\n",
        "    os.system(f\"git clone {MANAGER_REPO} {CUSTOM_NODES_DIR}\")\n",
        "else:\n",
        "    if UPDATE_COMFY_UI:\n",
        "        print(\"üîÑ Updating ComfyUI-Manager...\")\n",
        "        os.chdir(CUSTOM_NODES_DIR)\n",
        "        os.system(\"git reset --hard\")\n",
        "        os.system(\"git pull origin main\")\n",
        "    else:\n",
        "        print(\"‚è≠Ô∏è Skipping ComfyUI-Manager update.\")\n",
        "\n",
        "# ‚úÖ Install dependencies\n",
        "os.chdir(WORKSPACE)\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "os.system(\n",
        "    \"pip install xformers!=0.0.18 -r requirements.txt \"\n",
        "    \"--extra-index-url https://download.pytorch.org/whl/cu121 \"\n",
        "    \"--extra-index-url https://download.pytorch.org/whl/cu118 \"\n",
        "    \"--extra-index-url https://download.pytorch.org/whl/cu117\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Environment setup and update complete.\")\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd",
        "cellView": "form",
        "outputId": "ceb7fd6b-6547-4fc4-f3bc-acfab1ca92e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Starting download for https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_720p_14B_fp16.safetensors to the 'diffusion_models' directory...\n",
            "Downloading wan2.1_i2v_720p_14B_fp16.safetensors [------------------------------] 0.28% 87.45MB / 31272.29MB | 4.60 MB/s | ETA: 6773.15s"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "import urllib.parse\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# üîÑ Unified dropdown for selecting storage location\n",
        "MODEL_STORAGE_LOCATION = \"Google Drive (Persistent)\"  #@param [\"Google Drive (Persistent)\", \"Colab Filesystem (Notebook)\", \"Temporary SDUI Folder (Volatile)\"]\n",
        "MODEL_URL = \"https://tensor-models.7022ae40757f8d53295a57619de9b364.r2.cloudflarestorage.com/files/762555264535746522/f7278d22-91b0-44ea-ad8c-9c5bc002e315.safetensors\"  #@param {type:\"string\"}\n",
        "API_KEY = \"\"  #@param {type:\"string\"}\n",
        "MODEL_TYPE = \"checkpoints\"  #@param [\"checkpoints\", \"clip_vision\", \"vae\", \"loras\", \"controlnet\", \"style_models\", \"upscale_models\", \"diffusion_models\", \"hypernetworks\", \"gligen\", \"custom_nodes\"]\n",
        "\n",
        "# üîß Determine ComfyUI base path from dropdown\n",
        "def setup_environment():\n",
        "    if MODEL_STORAGE_LOCATION == \"Google Drive (Persistent)\":\n",
        "        print(\"üîó Mounting Google Drive...\")\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        base_dir = '/content/drive/MyDrive/ComfyUI'\n",
        "    elif MODEL_STORAGE_LOCATION == \"Colab Filesystem (Notebook)\":\n",
        "        base_dir = './ComfyUI'\n",
        "    else:\n",
        "        base_dir = './content/sdui'\n",
        "    return base_dir\n",
        "\n",
        "# üåç Setup environment\n",
        "BASE_DIR = setup_environment()\n",
        "\n",
        "# üìÅ Model destination folders from ComfyUI config structure\n",
        "MODEL_DIRS = {\n",
        "    'checkpoints': 'models/checkpoints',\n",
        "    'clip_vision': 'models/clip_vision',\n",
        "    'vae': 'models/vae',\n",
        "    'loras': 'models/loras',\n",
        "    'controlnet': 'models/controlnet',\n",
        "    'style_models': 'models/style_models',\n",
        "    'upscale_models': 'models/upscale_models',\n",
        "    'diffusion_models': 'models/diffusion_models',\n",
        "    'hypernetworks': 'models/hypernetworks',\n",
        "    'gligen': 'models/gligen',\n",
        "    'custom_nodes': 'custom_nodes',\n",
        "    'clip': 'models/clip',\n",
        "    'configs': 'models/configs',\n",
        "}\n",
        "\n",
        "# üîÅ Build full paths\n",
        "MODEL_DIRS = {key: os.path.join(BASE_DIR, path) for key, path in MODEL_DIRS.items()}\n",
        "\n",
        "# üèóÔ∏è Make sure the model folders exist\n",
        "for path in MODEL_DIRS.values():\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def format_progress_bar(percent, bar_length=30):\n",
        "    filled_length = int(bar_length * percent // 100)\n",
        "    bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "    return f\"[{bar}]\"\n",
        "\n",
        "# ‚¨áÔ∏è Download logic with progress\n",
        "def download_file(url, save_path, api_key=None):\n",
        "    try:\n",
        "        headers = {}\n",
        "        if api_key:\n",
        "            headers['Authorization'] = f'Bearer {api_key}'\n",
        "\n",
        "        response = requests.get(url, stream=True, allow_redirects=True, headers=headers)\n",
        "\n",
        "        if response.status_code == 403 and not api_key:\n",
        "            print(\"‚ö†Ô∏è Access denied. Retrying with API key...\")\n",
        "            return download_file(url, save_path, api_key=API_KEY)\n",
        "\n",
        "        response.raise_for_status()\n",
        "\n",
        "        filename = os.path.basename(urllib.parse.urlparse(url).path)\n",
        "        if 'content-disposition' in response.headers:\n",
        "            import cgi\n",
        "            _, params = cgi.parse_header(response.headers['content-disposition'])\n",
        "            filename = params.get('filename', filename)\n",
        "\n",
        "        save_path = os.path.join(save_path, filename)\n",
        "\n",
        "        total_size = int(response.headers.get('Content-Length', 0))\n",
        "        downloaded = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        with open(save_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "                    downloaded += len(chunk)\n",
        "\n",
        "                    percent = (downloaded / total_size) * 100\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    speed = downloaded / (1024 * 1024 * elapsed_time)  # MB/s\n",
        "                    time_left = (total_size - downloaded) / (speed * 1024 * 1024) if speed > 0 else 0\n",
        "                    progress_bar = format_progress_bar(percent)\n",
        "\n",
        "                    sys.stdout.write(\n",
        "                        f\"\\rüì• Downloading {filename} {progress_bar} {percent:.2f}% \"\n",
        "                        f\"{downloaded / (1024 * 1024):.2f}MB / {total_size / (1024 * 1024):.2f}MB | \"\n",
        "                        f\"{speed:.2f} MB/s | ETA: {time_left:.2f}s\"\n",
        "                    )\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "        print(f\"\\n‚úÖ Downloaded: {filename} to {save_path}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Error downloading {url}: {e}\")\n",
        "\n",
        "# üöÄ Start the download process\n",
        "if MODEL_URL:\n",
        "    print(f\"‚è≥ Starting download for {MODEL_URL} to ComfyUI/{MODEL_TYPE}...\")\n",
        "    save_path = MODEL_DIRS.get(MODEL_TYPE, os.path.join(BASE_DIR, 'models'))\n",
        "    download_file(MODEL_URL, save_path, api_key=API_KEY)\n",
        "else:\n",
        "    print(\"‚ùå No URL provided for download.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "cellView": "form",
        "outputId": "ddfda261-dfe3-48ae-b7c4-673e620584f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üìÅ Using storage at: /content/drive/MyDrive/ComfyUI\n",
            "üöÄ CUDA Available!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ba8568a5b26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0minstall_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# ‚úÖ Download and install Cloudflared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2ba8568a5b26>\u001b[0m in \u001b[0;36minstall_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üì¶ Installing missing module: {module}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanonicalize_state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_registry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAIN_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from .__helpers.model_descriptor import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/__helpers/loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcanonicalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanonicalize_state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmain_registry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAIN_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_descriptor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelDescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStateDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArchRegistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/__helpers/main_registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from ..architectures import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mATD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mCRAFT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/architectures/DAT/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mStateDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__arch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDAT\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spandrel/architectures/DAT/__arch/DAT.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meinops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRearrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/layers/torch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRearrangeMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReduceMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_einmix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_EinmixMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_specific\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_for_scriptable_torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0m__author__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Alex Rogozhnikov\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/_torch_specific.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# module import automatically registers ops in torchdynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mallow_ops_in_compiled_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/einops/_torch_specific.py\u001b[0m in \u001b[0;36mallow_ops_in_compiled_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallow_in_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_ops_in_compiled_graph failed to import torch: ensure pytorch >=2.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "#@title üîß ComfyUI Launcher (with VRAM Flags, Logs, Drive Options)\n",
        "#@markdown ### Setup Options\n",
        "storage_location = \"Google Drive\"  #@param [\"Google Drive\", \"Colab Runtime\", \"SDUI Temp Folder\"]\n",
        "show_logs = True  #@param {type:\"boolean\"}\n",
        "custom_flags = \"--highvram --dont-print-server\"  #@param {type:\"string\"}\n",
        "required_modules = ['torch', 'flask', 'flask_cors', 'requests', 'torchsde', 'spandrel', 'kornia', 'piexif', 'segment_anything']  #@param\n",
        "\n",
        "import os, subprocess, threading, time, socket\n",
        "from google.colab import drive\n",
        "\n",
        "# ‚úÖ Determine folder path\n",
        "if storage_location == \"Google Drive\":\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    folder_path = \"/content/drive/MyDrive/ComfyUI\"\n",
        "elif storage_location == \"SDUI Temp Folder\":\n",
        "    folder_path = \"/content/sdui/ComfyUI\"\n",
        "else:\n",
        "    folder_path = \"/content/ComfyUI\"\n",
        "\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "print(f\"üìÅ Using storage at: {folder_path}\")\n",
        "\n",
        "# ‚úÖ Check CUDA\n",
        "def check_cuda():\n",
        "    import torch\n",
        "    print(\"üöÄ CUDA Available!\" if torch.cuda.is_available() else \"‚ö†Ô∏è No GPU found, running on CPU.\")\n",
        "check_cuda()\n",
        "\n",
        "# ‚úÖ Install missing modules\n",
        "def install_module(module):\n",
        "    try:\n",
        "        __import__(module)\n",
        "    except ModuleNotFoundError:\n",
        "        print(f\"üì¶ Installing missing module: {module}\")\n",
        "        os.system(f\"pip install {module}\")\n",
        "        print(f\"‚úÖ {module} installed.\")\n",
        "\n",
        "for mod in required_modules:\n",
        "    install_module(mod)\n",
        "\n",
        "# ‚úÖ Download and install Cloudflared\n",
        "cloudflared_url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\"\n",
        "cloudflared_deb = os.path.join(folder_path, \"cloudflared.deb\")\n",
        "\n",
        "if not os.path.exists(\"/usr/bin/cloudflared\"):\n",
        "    print(\"üì• Downloading Cloudflared...\")\n",
        "    os.system(f\"wget -q --show-progress {cloudflared_url} -O {cloudflared_deb}\")\n",
        "    print(\"üõ†Ô∏è Installing Cloudflared...\")\n",
        "    os.system(f\"dpkg -i {cloudflared_deb}\")\n",
        "\n",
        "# ‚úÖ Tunnel Launch Function\n",
        "def launch_cloudflared(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        try:\n",
        "            with socket.create_connection((\"127.0.0.1\", port), timeout=1):\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    print(\"\\nüåê ComfyUI is ready. Launching Cloudflared tunnel...\\n\")\n",
        "    process = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    for line in process.stderr:\n",
        "        decoded = line.decode()\n",
        "        if \"trycloudflare.com\" in decoded:\n",
        "            print(\"üîó ComfyUI Public URL:\", decoded[decoded.find(\"http\"):], end='')\n",
        "\n",
        "threading.Thread(target=launch_cloudflared, daemon=True, args=(8188,)).start()\n",
        "\n",
        "# ‚úÖ Start ComfyUI\n",
        "print(f\"üöÄ Starting ComfyUI with flags: {custom_flags}\")\n",
        "main_path = os.path.join(folder_path, \"main.py\")\n",
        "\n",
        "if show_logs:\n",
        "    os.system(f\"python {main_path} {custom_flags}\")\n",
        "else:\n",
        "    os.system(f\"python {main_path} {custom_flags} > /dev/null 2>&1 &\")\n",
        "    print(\"‚úÖ ComfyUI is running silently. Enable 'Show Logs' to see output.\")\n"
      ]
    },
    {
      "source": [
        "#@title **üì¶ Compress & Clean Output Folder**\n",
        "#@markdown Use this tool to compress your output folder and clean it after.\n",
        "#@markdown Choose file format, compression level, and destination.\n",
        "!pip install py7zr\n",
        "!pip install rarfile\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import sys\n",
        "import subprocess\n",
        "import py7zr\n",
        "import rarfile\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# ‚úÖ **Mount Google Drive**\n",
        "mount_gdrive = True  #@param {type:\"boolean\"}\n",
        "if mount_gdrive:\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# ‚úÖ **User Options**\n",
        "output_folder = \"/content/drive/MyDrive/ComfyUI/output\"  #@param {type: \"string\"}\n",
        "archive_name = \"output\"  #@param {type: \"string\"}\n",
        "archive_destination = \"/content/drive/MyDrive/\"  #@param {type: \"string\"}\n",
        "\n",
        "file_type = \"zip\"  #@param [\"zip\", \"7z\", \"rar\"]\n",
        "compression_level = \"normal\"  #@param [\"store\", \"fast\", \"normal\", \"high\", \"maximum\"]\n",
        "\n",
        "# üî• **Compression Level Mapping**\n",
        "compression_map = {\n",
        "    'store': 0, 'fast': 1, 'normal': 5, 'high': 7, 'maximum': 9\n",
        "}\n",
        "\n",
        "def compress_and_clean_output(output_folder, archive_name, archive_destination, file_type, compression_level):\n",
        "    \"\"\"Compresses and cleans the output folder.\"\"\"\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        print(f\"‚ùå Error: The folder '{output_folder}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(archive_destination):\n",
        "        print(f\"‚ùå Error: The destination folder '{archive_destination}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    total_original_size = sum(\n",
        "        os.path.getsize(os.path.join(root, file))\n",
        "        for root, _, files in os.walk(output_folder)\n",
        "        for file in files\n",
        "    )\n",
        "\n",
        "    extension = {'zip': '.zip', '7z': '.7z', 'rar': '.rar'}[file_type]\n",
        "    archive_path = os.path.join(archive_destination, f\"{archive_name}{extension}\")\n",
        "    compression_value = compression_map[compression_level]\n",
        "\n",
        "    # ‚úÖ **ZIP Compression**\n",
        "    if file_type == 'zip':\n",
        "        compression = zipfile.ZIP_STORED if compression_level == 'store' else zipfile.ZIP_DEFLATED\n",
        "        with zipfile.ZipFile(archive_path, 'w', compression) as zipf:\n",
        "            for root, _, files in os.walk(output_folder):\n",
        "                for file in tqdm(files, desc=\"üì¶ Compressing as .zip\", unit=\"file\"):\n",
        "                    zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), output_folder))\n",
        "\n",
        "    # ‚úÖ **7Z Compression**\n",
        "    elif file_type == '7z':\n",
        "        with py7zr.SevenZipFile(archive_path, 'w', filters=[{'id': py7zr.FILTER_LZMA2, 'preset': compression_value}]) as archive:\n",
        "            for root, _, files in os.walk(output_folder):\n",
        "                for file in tqdm(files, desc=\"üì¶ Compressing as .7z\", unit=\"file\"):\n",
        "                    archive.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), output_folder))\n",
        "\n",
        "    # ‚úÖ **RAR Compression**\n",
        "    elif file_type == 'rar':\n",
        "        try:\n",
        "            print(\"üì¶ Compressing as .rar (This may take some time, progress bar not supported)\")\n",
        "            subprocess.run(['rar', 'a', '-m' + str(compression_value), archive_path, output_folder], check=True)\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(\"‚ùå Failed to create .rar archive. Install 'rar' using 'apt-get install rar'.\")\n",
        "\n",
        "    total_compressed_size = os.path.getsize(archive_path)\n",
        "    compression_percentage = (1 - (total_compressed_size / total_original_size)) * 100 if total_original_size > 0 else 0\n",
        "\n",
        "    print(f\"üì¶ Original size: {total_original_size / 1024**2:.2f} MB\")\n",
        "    print(f\"üì¶ Compressed size: {total_compressed_size / 1024**2:.2f} MB\")\n",
        "    print(f\"üì¶ Compression percentage: {compression_percentage:.2f}%\")\n",
        "\n",
        "    # ‚úÖ **Delete original files**\n",
        "    for filename in os.listdir(output_folder):\n",
        "        file_path = os.path.join(output_folder, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f'‚ùå Failed to delete {file_path}. Reason: {e}')\n",
        "\n",
        "    print(f\"‚úÖ Successfully compressed and cleaned {output_folder}\")\n",
        "\n",
        "# üî• **Run the function**\n",
        "compress_and_clean_output(output_folder, archive_name, archive_destination, file_type, compression_level)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "devAdoTZi_Qa",
        "outputId": "2507d99d-d23a-4a03-cc94-f2a185d50d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.7.0)\n",
            "Requirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (3.22.0)\n",
            "Requirement already satisfied: pyzstd>=0.15.9 in /usr/local/lib/python3.11/dist-packages (from py7zr) (0.16.2)\n",
            "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.1.1)\n",
            "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.0.3)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.0.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from py7zr) (1.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from py7zr) (5.9.5)\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üì¶ Compressing as .zip: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:18<00:00,  3.85file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Original size: 336.22 MB\n",
            "üì¶ Compressed size: 335.62 MB\n",
            "üì¶ Compression percentage: 0.18%\n",
            "‚úÖ Successfully compressed and cleaned /content/drive/MyDrive/ComfyUI/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZ1B9CWu-CJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}